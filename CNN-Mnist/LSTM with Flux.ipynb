{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /home/emoryfreitas/.julia/compiled/v1.0/Flux/QdkVy.ji for Flux [587475ba-b771-5e3f-ad9e-33799f191a9c]\n",
      "└ @ Base loading.jl:1190\n",
      "┌ Info: CUDAdrv.jl failed to initialize, GPU functionality unavailable (set JULIA_CUDA_SILENT or JULIA_CUDA_VERBOSE to silence or expand this message)\n",
      "└ @ CUDAdrv /home/emoryfreitas/.julia/packages/CUDAdrv/aBgcd/src/CUDAdrv.jl:69\n"
     ]
    }
   ],
   "source": [
    "using Flux, Flux.Data.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Flux.Data.Sentiment.train();\n",
    "test_dataset = Flux.Data.Sentiment.test();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m HTML_Entities ── v1.0.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m WordTokenizers ─ v0.5.4\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m StrTables ────── v1.0.1\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Project.toml`\n",
      " \u001b[90m [796a5d58]\u001b[39m\u001b[92m + WordTokenizers v0.5.4\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Manifest.toml`\n",
      " \u001b[90m [7693890a]\u001b[39m\u001b[92m + HTML_Entities v1.0.0\u001b[39m\n",
      " \u001b[90m [9700d1a9]\u001b[39m\u001b[92m + StrTables v1.0.1\u001b[39m\n",
      " \u001b[90m [796a5d58]\u001b[39m\u001b[92m + WordTokenizers v0.5.4\u001b[39m\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m HTML_Entities → `~/.julia/packages/HTML_Entities/g4t7p/deps/build.log`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling WordTokenizers [796a5d58-b03d-544a-977e-18100b691f6e]\n",
      "└ @ Base loading.jl:1192\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.add(\"WordTokenizers\")\n",
    "using WordTokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(\n",
    "    LSTM(3,2), \n",
    "    Dense(2,1),\n",
    "\n",
    "    # Finally, softmax to get nice probabilities\n",
    "    softmax,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADAM(0.001, (0.9, 0.999), IdDict{Any,Any}())"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `loss()` calculates the crossentropy loss between our prediction `y_hat`\n",
    "# (calculated from `model(x)`) and the ground truth `y`.  We augment the data\n",
    "# a bit, adding gaussian random noise to our image to make it more robust.\n",
    "function L(x, y)\n",
    "    # We augment `x` a little bit here, adding in random noise\n",
    "    x_aug = x .+ 0.1f0*randn(eltype(x), size(x))\n",
    "\n",
    "    y_hat = model(x_aug)\n",
    "    return crossentropy(y_hat, y)\n",
    "end\n",
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))\n",
    "\n",
    "# Train our model with the given training set using the ADAM optimizer and\n",
    "# printing out performance against the test set as we go.\n",
    "opt = ADAM(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: Flux not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: Flux not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[1]:1"
     ]
    }
   ],
   "source": [
    "Flux.train!(L, params(model), train_dataset, opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.5",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
